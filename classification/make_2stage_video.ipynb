{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.transforms import Normalize, ToTensor, Resize, Compose\n",
    "from torchvision.datasets import ImageFolder\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from torch import nn\n",
    "import torch\n",
    "import os\n",
    "import torch.functional as F\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import t2np, np_softmax\n",
    "from data import get_preprocessing\n",
    "from model import SignModel\n",
    "\n",
    "\n",
    "def draw_rpn_prediction(img, bboxes):\n",
    "    img = np.array(img)\n",
    "    import cv2\n",
    "    for b in bboxes:\n",
    "        cv2.rectangle(img, (int(b[0]), int(b[1])), (int(b[2]), int(b[3])), (255,0,0), 3)\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "def draw_prediction(img, bboxes, scores, classes):\n",
    "    img = np.array(img)\n",
    "    import cv2\n",
    "    for b, c, s in zip(bboxes, classes, scores):\n",
    "        cv2.rectangle(img, (int(b[0]), int(b[1])), (int(b[2]), int(b[3])), (0,0,255), 3)\n",
    "        cv2.putText(img, '{} ({:d})'.format(c, int(100*s)), (int(b[0]), int(b[1])-10), 1, 2, (0, 0, 0), 6)\n",
    "        cv2.putText(img, '{} ({:d})'.format(c, int(100*s)), (int(b[0]), int(b[1])-10), 1, 2, (255, 255, 255), 3)\n",
    "    return Image.fromarray(img)\n",
    "    \n",
    "\n",
    "def gather_crops(img, t):\n",
    "    crops = []\n",
    "    boxes = []\n",
    "    for _, row in t.iterrows():\n",
    "        xtl, ytl, xbr, ybr = map(lambda x: int(0.5+float(x)), (row.xtl, row.ytl, row.xbr, row.ybr))\n",
    "        boxes.append((xtl, ytl, xbr, ybr))\n",
    "        crops.append(val_transform(img.crop(boxes[-1]))[None, ...])\n",
    "        \n",
    "    if len(crops) > 0:\n",
    "        return torch.cat(crops).half().cuda(), np.array(boxes)\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "impaths = sorted(glob('/media/grisha/hdd/icevision/ice/images/2018-03-23_1352_right/*.jpg'))\n",
    "df = pd.read_csv('/media/grisha/hdd/icevision/models/Simultaneous-Traffic-Sign-Detection-and-Classification-with-RetinaNet/2018-03-23_1352_right.csv')\n",
    "id2class = ImageFolder('classification/classification_data/train/').classes\n",
    "val_transform = get_preprocessing(train=False)\n",
    "\n",
    "model = SignModel().half().cuda()\n",
    "checkpoint = torch.load(os.path.join('classification/class_ckpts/init/2_ckpt.pth'))\n",
    "model.load_state_dict(checkpoint[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8539/8539 [15:57<00:00,  9.05it/s]\n"
     ]
    }
   ],
   "source": [
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output_cls.avi',fourcc, 30.0, (1224,1024))\n",
    "\n",
    "for impath in tqdm(impaths):\n",
    "    imname = os.path.basename(impath)\n",
    "    img = Image.open(impath)\n",
    "\n",
    "    t = df[df.imname==imname]\n",
    "    crops, boxes = gather_crops(img, t)\n",
    "    if boxes is not None:\n",
    "        img = draw_rpn_prediction(img, boxes)\n",
    "\n",
    "        y_hat = np_softmax(t2np(model(crops)))\n",
    "\n",
    "        amax = y_hat.argmax(-1).flatten()\n",
    "        scores = y_hat.max(-1).flatten()\n",
    "        preds = np.array([id2class[x] for x in amax])\n",
    "        area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "\n",
    "        idx = (scores > 0.7) & (preds != 'other') & (area > 100)\n",
    "        scores = scores[idx]\n",
    "        preds = preds[idx]\n",
    "        boxes = boxes[idx]\n",
    "\n",
    "        img = draw_prediction(img, boxes, scores, preds)\n",
    "\n",
    "    img = np.array(img.resize((1224, 1024)))[..., ::-1]\n",
    "    out.write(img)\n",
    "\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
